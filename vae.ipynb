{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1557014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.datasets import make_moons\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f572953",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc91562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class VAEOutput:\n",
    "    \"\"\"\n",
    "    Dataclass for VAE output.\n",
    "    \n",
    "    Attributes:\n",
    "        z_dist (torch.distributions.Distribution): The distribution of the latent variable z.\n",
    "        z_sample (torch.Tensor): The sampled value of the latent variable z.\n",
    "        x_recon (torch.Tensor): The reconstructed output from the VAE.\n",
    "        loss (torch.Tensor): The overall loss of the VAE.\n",
    "        loss_recon (torch.Tensor): The reconstruction loss component of the VAE loss.\n",
    "        loss_kl (torch.Tensor): The KL divergence component of the VAE loss.\n",
    "    \"\"\"\n",
    "    z_dist: torch.distributions.Distribution\n",
    "    z_sample: torch.Tensor\n",
    "    x_dist: torch.distributions.Distribution\n",
    "    x_recon: torch.Tensor\n",
    "    \n",
    "    loss: Optional[torch.Tensor] = None\n",
    "    loss_recon: Optional[torch.Tensor] = None\n",
    "    loss_kl: Optional[torch.Tensor] = None\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational Autoencoder (VAE) class.\n",
    "    \n",
    "    Args:\n",
    "        input_dim (int): Dimensionality of the input data.\n",
    "        hidden_dim (int | list[int]): Dimensionality of the hidden layers.\n",
    "        latent_dim (int): Dimensionality of the latent space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dim: int | list[int], latent_dim: int):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        encoder_layers_list = []\n",
    "        if type(hidden_dim) != list:\n",
    "            encoder_layers_list.append(nn.Linear(input_dim, hidden_dim))\n",
    "            encoder_layers_list.append(nn.LeakyReLU())\n",
    "            encoder_layers_list.append(nn.Linear(hidden_dim, 2 * latent_dim))\n",
    "        else:\n",
    "            self.hidden_dim = hidden_dim.copy()\n",
    "            encoder_layers_list.append(nn.Linear(input_dim, hidden_dim[0]))\n",
    "            encoder_layers_list.append(nn.LeakyReLU())\n",
    "            for i in range(len(hidden_dim[1:])):\n",
    "                encoder_layers_list.append(nn.Linear(hidden_dim[i], hidden_dim[i+1]))\n",
    "                encoder_layers_list.append(nn.LeakyReLU())\n",
    "            encoder_layers_list.append(nn.Linear(hidden_dim[-1], 2 * latent_dim))\n",
    "        \n",
    "        self.encoder = nn.Sequential(*encoder_layers_list)\n",
    "\n",
    "        decoder_layers_list = []\n",
    "        if type(hidden_dim) != list:\n",
    "            decoder_layers_list.append(nn.Linear(latent_dim, hidden_dim))\n",
    "            decoder_layers_list.append(nn.LeakyReLU())\n",
    "            decoder_layers_list.append(nn.Linear(hidden_dim, 2 * input_dim))\n",
    "        else:\n",
    "            hidden_dim_decoder = hidden_dim[::-1]\n",
    "            decoder_layers_list.append(nn.Linear(latent_dim, hidden_dim_decoder[0]))\n",
    "            decoder_layers_list.append(nn.LeakyReLU())\n",
    "            for i in range(len(hidden_dim_decoder[1:])):\n",
    "                decoder_layers_list.append(nn.Linear(hidden_dim_decoder[i], hidden_dim_decoder[i+1]))\n",
    "                decoder_layers_list.append(nn.LeakyReLU())\n",
    "            decoder_layers_list.append(nn.Linear(hidden_dim_decoder[-1], 2 * input_dim))\n",
    "\n",
    "        self.decoder = nn.Sequential(*decoder_layers_list)\n",
    "\n",
    "        print(f\"Encoder: {encoder_layers_list}\")\n",
    "        print(f\"Decoder: {decoder_layers_list}\")\n",
    "\n",
    "    def encode(self, x: torch.Tensor, eps: float = 1e-8):\n",
    "        \"\"\"\n",
    "        Encodes the input data into the latent space.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input data.\n",
    "            eps (float): Small value to avoid numerical instability.\n",
    "        \n",
    "        Returns:\n",
    "            torch.distributions.MultivariateNormal: Normal distribution of the encoded data.\n",
    "        \"\"\"\n",
    "        params = self.encoder(x)\n",
    "        means = params[:, :self.latent_dim]\n",
    "        covs = torch.diag_embed(torch.exp(params[:, self.latent_dim:]) + eps)\n",
    "        return torch.distributions.MultivariateNormal(means, covariance_matrix=covs)\n",
    "    \n",
    "    def reparameterize(self, dist: torch.distributions.Distribution):\n",
    "        \"\"\"\n",
    "        Reparameterizes the encoded data to sample from the latent space.\n",
    "        \n",
    "        Args:\n",
    "            dist (torch.distributions.MultivariateNormal): Normal distribution of the encoded data.\n",
    "        Returns:\n",
    "            torch.Tensor: Sampled data from the latent space.\n",
    "        \"\"\"\n",
    "        return dist.rsample()\n",
    "    \n",
    "    def decode(self, z: torch.Tensor, eps: float = 1e-8):\n",
    "        \"\"\"\n",
    "        Decodes the data from the latent space into the original input space.\n",
    "        \n",
    "        Args:\n",
    "            z (torch.Tensor): Data in the latent space.\n",
    "            eps (float): Small value to avoid numerical instability.\n",
    "        \n",
    "        Returns:\n",
    "            torch.distributions.MultivariateNormal: Normal distribution of the decoded data.\n",
    "        \"\"\"\n",
    "        params = self.decoder(z)\n",
    "        means = params[:, :self.input_dim]\n",
    "        covs = torch.diag_embed(torch.exp(params[:, self.input_dim:]) + eps)\n",
    "        return torch.distributions.MultivariateNormal(means, covariance_matrix=covs)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, compute_loss: bool = True):\n",
    "        \"\"\"\n",
    "        Performs a forward pass of the VAE.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input data.\n",
    "            compute_loss (bool): Whether to compute the loss or not.\n",
    "        \n",
    "        Returns:\n",
    "            VAEOutput: VAE output dataclass.\n",
    "        \"\"\"\n",
    "        \n",
    "        z_dist = self.encode(x)\n",
    "        z = self.reparameterize(z_dist)\n",
    "        x_dist = self.decode(z)\n",
    "        recon_x = x_dist.mean\n",
    "        \n",
    "        if not compute_loss:\n",
    "            return VAEOutput(\n",
    "                z_dist=z_dist,\n",
    "                z_sample=z,\n",
    "                x_dist=x_dist,\n",
    "                x_recon=recon_x,\n",
    "            )\n",
    "        \n",
    "        # Compute loss terms\n",
    "        x_diff = x - recon_x\n",
    "        diagonals = torch.diagonal(x_dist.covariance_matrix, dim1=-2, dim2=-1)\n",
    "        loss_recon = torch.log(torch.prod(diagonals, dim=-1)).mean() / 2\n",
    "        cov_inv = torch.diag_embed(1.0 / diagonals)\n",
    "        loss_recon += torch.unsqueeze(x_diff, 1).bmm(cov_inv).bmm(torch.unsqueeze(x_diff, -1)).mean() / 2\n",
    "        std_normal = torch.distributions.MultivariateNormal(\n",
    "            torch.zeros_like(z, device=z.device),\n",
    "            scale_tril=torch.eye(z.shape[-1], device=z.device).unsqueeze(0).expand(z.shape[0], -1, -1),\n",
    "        )\n",
    "        loss_kl = torch.distributions.kl.kl_divergence(z_dist, std_normal).mean()\n",
    "        \n",
    "        loss = loss_recon + loss_kl\n",
    "        \n",
    "        return VAEOutput(\n",
    "            z_dist=z_dist,\n",
    "            z_sample=z,\n",
    "            x_dist=x_dist,\n",
    "            x_recon=recon_x,\n",
    "            loss=loss,\n",
    "            loss_recon=loss_recon,\n",
    "            loss_kl=loss_kl,\n",
    "        )\n",
    "    \n",
    "    def log_marginal(self, x: torch.Tensor, num_samples: int = 5):\n",
    "        z_dist = self.encode(x)\n",
    "        z_mean = z_dist.mean\n",
    "        std_normal = torch.distributions.MultivariateNormal(\n",
    "            torch.zeros_like(z_mean, device=z_mean.device),\n",
    "            scale_tril=torch.eye(z_mean.shape[-1], device=z_mean.device).unsqueeze(0).expand(z_mean.shape[0], -1, -1),\n",
    "        )\n",
    "        if num_samples < 2:\n",
    "            z = z_dist.sample()\n",
    "            x_dist = self.decode(z)\n",
    "            log_marg = x_dist.log_prob(x)\n",
    "            log_marg += std_normal.log_prob(z)\n",
    "            log_marg -= z_dist.log_prob(z)\n",
    "            return log_marg.detach().cpu().flatten()\n",
    "        total_marginal = 0\n",
    "        for _ in range(num_samples):\n",
    "            z = z_dist.sample()\n",
    "            x_dist = self.decode(z)\n",
    "            sample_marginal = torch.exp(x_dist.log_prob(x))\n",
    "            sample_marginal *= torch.exp(std_normal.log_prob(z)) / num_samples\n",
    "            sample_marginal /= torch.exp(z_dist.log_prob(z))\n",
    "            total_marginal += sample_marginal\n",
    "        return torch.log(total_marginal.detach().cpu().flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26f2e17",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_test_split(train_size: int, test_size: int, noise: float = 0.15):\n",
    "    X_train, y_train = make_moons(n_samples=train_size, noise=noise, random_state=123)\n",
    "    X_test, y_test = make_moons(n_samples=test_size, noise=(noise * 1.4), random_state=123)\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "\n",
    "class MoonsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "        self.X = torch.from_numpy(self._X).float()\n",
    "        self.y = torch.from_numpy(self._y.reshape(-1, 1)).float()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a15319",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d2d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch_size = 150\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 1000\n",
    "input_dim = 2\n",
    "latent_dim = 2\n",
    "hidden_dim = [256, 128, 64]\n",
    "\n",
    "train_split, test_split = gen_train_test_split(3000, 600)\n",
    "train_loader = DataLoader(MoonsDataset(*train_split), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(MoonsDataset(*test_split), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: VAE, dataloader: DataLoader, optimizer: torch.optim.Optimizer):\n",
    "    \"\"\"\n",
    "    Trains the model on the given data.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        dataloader (torch.utils.data.DataLoader): The data loader.\n",
    "        optimizer: The optimizer.\n",
    "    \"\"\"\n",
    "    model.train()  # Set the model to training mode\n",
    "    loss_total = 0.0\n",
    "    loss_recon = 0.0\n",
    "    loss_kl = 0.0\n",
    "    for data, _ in dataloader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        output = model(data, compute_loss=True)  # Forward pass\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()  # Update the model parameters\n",
    "        loss_total += loss.item()\n",
    "        loss_recon += output.loss_recon.item()\n",
    "        loss_kl += output.loss_kl.item()\n",
    "    n_batchs = len(dataloader)\n",
    "    loss_total /= n_batchs\n",
    "    loss_recon /= n_batchs\n",
    "    loss_kl /= n_batchs\n",
    "    return loss_total, loss_recon, loss_kl\n",
    "\n",
    "def test(model: VAE, dataloader: DataLoader):\n",
    "    \"\"\"\n",
    "    Tests the model on the given data.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The model to test.\n",
    "        dataloader (torch.utils.data.DataLoader): The data loader.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    loss_total = 0.0\n",
    "    loss_recon = 0.0\n",
    "    loss_kl = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in dataloader:\n",
    "            data = data.to(device)\n",
    "            output = model(data, compute_loss=True)  # Forward pass\n",
    "        loss_total += output.loss.item()\n",
    "        loss_recon += output.loss_recon.item()\n",
    "        loss_kl += output.loss_kl.item()\n",
    "    n_batchs = len(dataloader)\n",
    "    loss_total /= n_batchs\n",
    "    loss_recon /= n_batchs\n",
    "    loss_kl /= n_batchs\n",
    "    return loss_total, loss_recon, loss_kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dee731",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Variational Autoencoder...\")\n",
    "model_VAE = VAE(input_dim=input_dim, hidden_dim=hidden_dim, latent_dim=latent_dim).to(device)\n",
    "print(model_VAE)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_VAE.parameters(), lr=learning_rate)\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "for epoch in trange(1, num_epochs + 1, desc='Training', unit='epoch'):\n",
    "    train_loss = train(model_VAE, train_loader, optimizer)\n",
    "    test_loss = test(model_VAE, test_loader)\n",
    "    train_loss_history.append(train_loss)\n",
    "    test_loss_history.append(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e894b010",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee465dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "# Train data\n",
    "cls_mask = train_split[1].astype(bool)\n",
    "plt.scatter(train_split[0][cls_mask, 0], train_split[0][cls_mask, 1], color='orange', label='Train 1')\n",
    "plt.scatter(train_split[0][~cls_mask, 0], train_split[0][~cls_mask, 1], color='cyan', label='Train 0')\n",
    "# Test data\n",
    "cls_mask = test_split[1].astype(bool)\n",
    "plt.scatter(test_split[0][cls_mask, 0], test_split[0][cls_mask, 1], color='red', marker='x', label='Test 1')\n",
    "plt.scatter(test_split[0][~cls_mask, 0], test_split[0][~cls_mask, 1], color='blue', marker='x', label='Test 1')\n",
    "\n",
    "plt.title('Training and testing data')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9589e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_label = ('Total', 'Reconstruction', 'KL')\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
    "\n",
    "for i, loss_label in enumerate(losses_label):\n",
    "    ax = axs[i]\n",
    "    ax.plot(\n",
    "        range(1, len(train_loss_history) + 1),\n",
    "        [l[i] for l in train_loss_history],\n",
    "        label='Training',\n",
    "    )\n",
    "    ax.plot(\n",
    "        range(1, len(test_loss_history) + 1),\n",
    "        [l[i] for l in test_loss_history],\n",
    "        label='Testing',\n",
    "    )\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel(f'{loss_label} loss')\n",
    "    ax.set_title(f'{loss_label} loss evolution')\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f35d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space(model: VAE):\n",
    "    model.eval()\n",
    "    z_all = []\n",
    "    y_all = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(train_loader, desc='Encoding', unit='batch'):\n",
    "            z = model.encode(data.to(device))\n",
    "            z = z.mean\n",
    "            z_all.append(z.detach().cpu().numpy())\n",
    "            y_all.append(target.numpy())\n",
    "    z_all = np.concatenate(z_all, axis=0)\n",
    "    y_all = np.concatenate(y_all, axis=0)\n",
    "    cls_mask = y_all.astype(bool).flatten()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(z_all[cls_mask, 0], z_all[cls_mask, 1], color='red')\n",
    "    plt.scatter(z_all[~cls_mask, 0], z_all[~cls_mask, 1], color='blue')\n",
    "    plt.title(f'Latent projection')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_random_samples(model: VAE, num_samples: int = 200):\n",
    "    model.eval()\n",
    "    std_normal = torch.distributions.MultivariateNormal(\n",
    "        torch.zeros(model.latent_dim, device=device),\n",
    "        covariance_matrix=torch.eye(model.latent_dim, device=device),\n",
    "    )\n",
    "    x_dist = model.decode(std_normal.sample((num_samples,)))\n",
    "    samples = x_dist.sample().cpu()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(samples[:, 0], samples[:, 1])\n",
    "    plt.title('Generated samples')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_log_marginal(model: VAE, num_samples: int = 5):\n",
    "    data = train_split[0]\n",
    "    xmin, ymin = np.floor(data.min(axis=0))\n",
    "    xmax, ymax = np.ceil(data.max(axis=0))\n",
    "    xs = np.linspace(xmin, xmax, num=200)\n",
    "    ys = np.linspace(ymin, ymax, num=200)\n",
    "    xx, yy = np.meshgrid(xs, ys)\n",
    "    X = np.column_stack((xx.ravel(), yy.ravel()))\n",
    "    X = torch.from_numpy(X).float().to(device)\n",
    "    log_probs = model.log_marginal(X, num_samples)\n",
    "    log_probs = log_probs.numpy().reshape((xs.size, ys.size))\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    img = ax.imshow(\n",
    "        log_probs,\n",
    "        cmap='magma',\n",
    "        extent=[xmin, xmax, ymin, ymax],\n",
    "        origin='lower',\n",
    "        aspect='auto',\n",
    "        interpolation='nearest',\n",
    "    )\n",
    "    fig.colorbar(img, ax=ax, label='Log-verossimilhança')\n",
    "    cls_mask = train_split[1].astype(bool)\n",
    "    pos_points = data[cls_mask]\n",
    "    neg_points = data[~cls_mask]\n",
    "    ax.scatter(pos_points[::10, 0], pos_points[::10, 1], color='red', alpha=0.5)\n",
    "    ax.scatter(neg_points[::10, 0], neg_points[::10, 1], color='blue', alpha=0.5)\n",
    "    ax.set_title('Log-verossimilhança aproximada')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06872eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent_space(model_VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a9a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_samples(model_VAE, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_log_marginal(model_VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8daa4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
