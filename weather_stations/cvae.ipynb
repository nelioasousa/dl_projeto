{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Distribution, MultivariateNormal, kl_divergence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dataclass(kw_only=True)\n",
    "# class CVAEOutput:\n",
    "#     \"\"\"\n",
    "#     Dataclass for CVAE output.\n",
    "    \n",
    "#     Attributes:\n",
    "#         recog_pass (bool): Whether is a recognition pass or a generation pass\n",
    "#         x (torch.Tensor): input x\n",
    "#         y (torch.Tensor): input y\n",
    "#         z_prior_dist (torch.distributions.Distribution): Prior distribution of the latent variable z.\n",
    "#         z_prior_sample (torch.Tensor): Sampled value of the prior of latent variable z.\n",
    "#         z_recog_dist (torch.distributions.Distribution): Recognition distribution of the latent variable z.\n",
    "#         z_recog_sample (torch.Tensor): Sampled value of the recognition distribution of latent variable z.\n",
    "#         y_recon (torch.Tensor): The reconstructed y.\n",
    "#         loss (torch.Tensor): The overall loss of the CVAE.\n",
    "#         loss_recon (torch.Tensor): The reconstruction loss component of the CVAE loss.\n",
    "#         loss_kl (torch.Tensor): The KL divergence component of the CVAE loss.\n",
    "#         loss_gen (torch.Tensor): Same `loss_recon` but compute from a generation of `y`.\n",
    "#     \"\"\"\n",
    "#     recog_pass: bool\n",
    "#     x: torch.Tensor\n",
    "#     y: torch.Tensor\n",
    "#     z_prior_dist: Optional[Distribution] = None\n",
    "#     z_prior_sample: Optional[torch.Tensor] = None\n",
    "#     z_recog_dist: Optional[Distribution] = None\n",
    "#     z_recog_sample: Optional[torch.Tensor] = None\n",
    "#     y_recon: Optional[torch.Tensor] = None\n",
    "    \n",
    "#     loss: Optional[torch.Tensor] = None\n",
    "#     loss_recon: Optional[torch.Tensor] = None\n",
    "#     loss_kl: Optional[torch.Tensor] = None\n",
    "#     loss_gen: Optional[torch.Tensor] = None\n",
    "\n",
    "\n",
    "# class CVAE(nn.Module):\n",
    "#     \"\"\"Conditional Variational Autoencoder (CVAE) class.\n",
    "\n",
    "#     Args:\n",
    "#         x_dim (int): Dimensionality of the condition x.\n",
    "#         y_dim (int): Dimensionality of the input/output data y.\n",
    "#         hidden_dim (int): Dimensionality of the hidden layers.\n",
    "#         latent_dim (int): Dimensionality of the latent space.\n",
    "#     \"\"\"\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         x_dim: int,\n",
    "#         y_dim: int,\n",
    "#         latent_dim: int,\n",
    "#         prior_hidden_dim: int | list[int],\n",
    "#         gen_hidden_dim: int | list[int],\n",
    "#         recog_hidden_dim: int | list[int],\n",
    "#     ):\n",
    "#         super(CVAE, self).__init__()\n",
    "\n",
    "#         self.x_dim = x_dim\n",
    "#         self.y_dim = y_dim\n",
    "#         self.latent_dim = latent_dim\n",
    "#         self.prior_hidden_dim = prior_hidden_dim\n",
    "#         self.gen_hidden_dim = gen_hidden_dim\n",
    "#         self.recog_hidden_dim = recog_hidden_dim\n",
    "\n",
    "#         # Prior network: p(z|x)\n",
    "#         prior_layers_list = []\n",
    "#         if type(prior_hidden_dim) != list:\n",
    "#             prior_layers_list.append(nn.Linear(x_dim, prior_hidden_dim))\n",
    "#             prior_layers_list.append(nn.LeakyReLU())\n",
    "#             prior_layers_list.append(nn.Linear(prior_hidden_dim, 2 * latent_dim))\n",
    "#         else:\n",
    "#             self.hidden_dim = prior_hidden_dim.copy()\n",
    "#             prior_layers_list.append(nn.Linear(x_dim, prior_hidden_dim[0]))\n",
    "#             prior_layers_list.append(nn.LeakyReLU())\n",
    "#             for i in range(len(prior_hidden_dim[1:])):\n",
    "#                 prior_layers_list.append(nn.Linear(prior_hidden_dim[i], prior_hidden_dim[i+1]))\n",
    "#                 prior_layers_list.append(nn.LeakyReLU())\n",
    "#             prior_layers_list.append(nn.Linear(prior_hidden_dim[-1], 2 * latent_dim))\n",
    "        \n",
    "#         self.prior_network = nn.Sequential(*prior_layers_list)\n",
    "\n",
    "#         # Generation network: p(y|x,z)\n",
    "#         gen_layers_list = []\n",
    "#         if type(gen_hidden_dim) != list:\n",
    "#             gen_layers_list.append(nn.Linear(x_dim + latent_dim, gen_hidden_dim))\n",
    "#             gen_layers_list.append(nn.LeakyReLU())\n",
    "#             gen_layers_list.append(nn.Linear(gen_hidden_dim, y_dim))\n",
    "#         else:\n",
    "#             self.gen_hidden_dim = gen_hidden_dim.copy()\n",
    "#             gen_layers_list.append(nn.Linear(x_dim + latent_dim, gen_hidden_dim[0]))\n",
    "#             gen_layers_list.append(nn.LeakyReLU())\n",
    "#             for i in range(len(gen_hidden_dim[1:])):\n",
    "#                 gen_layers_list.append(nn.Linear(gen_hidden_dim[i], gen_hidden_dim[i+1]))\n",
    "#                 gen_layers_list.append(nn.LeakyReLU())\n",
    "#             gen_layers_list.append(nn.Linear(gen_hidden_dim[-1], y_dim))\n",
    "        \n",
    "#         self.gen_network = nn.Sequential(*gen_layers_list)\n",
    "\n",
    "#         if y_dim == 1:\n",
    "#             self.loss = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "#         else:\n",
    "#             self.loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "#         # Recognition/Inference network: p(z|x,y)\n",
    "#         recog_layers_list = []\n",
    "#         if type(recog_hidden_dim) != list:\n",
    "#             recog_layers_list.append(nn.Linear(x_dim + y_dim, recog_hidden_dim))\n",
    "#             recog_layers_list.append(nn.LeakyReLU())\n",
    "#             recog_layers_list.append(nn.Linear(recog_hidden_dim, 2 * latent_dim))\n",
    "#         else:\n",
    "#             self.recog_hidden_dim = recog_hidden_dim.copy()\n",
    "#             recog_layers_list.append(nn.Linear(x_dim + y_dim, recog_hidden_dim[0]))\n",
    "#             recog_layers_list.append(nn.LeakyReLU())\n",
    "#             for i in range(len(recog_hidden_dim[1:])):\n",
    "#                 recog_layers_list.append(nn.Linear(recog_hidden_dim[i], recog_hidden_dim[i+1]))\n",
    "#                 recog_layers_list.append(nn.LeakyReLU())\n",
    "#             recog_layers_list.append(nn.Linear(recog_hidden_dim[-1], 2 * latent_dim))\n",
    "        \n",
    "#         self.recog_network = nn.Sequential(*recog_layers_list)\n",
    "\n",
    "#     def reconstruct(self, x: torch.Tensor, z: torch.Tensor, raw: bool = False):\n",
    "#         xz = torch.concatenate((x, z), dim=1)\n",
    "#         y_recon = self.gen_network(xz)\n",
    "#         if not raw:\n",
    "#             if self.y_dim == 1:\n",
    "#                 y_recon = F.sigmoid(y_recon)\n",
    "#             else:\n",
    "#                 y_recon = F.softmax(y_recon, dim=-1)\n",
    "#         return y_recon\n",
    "\n",
    "#     def recognize(self, x: torch.Tensor, y: torch.Tensor, eps: float = 1e-8):\n",
    "#         xy = torch.concatenate((x, y), dim=1)\n",
    "#         params = self.recog_network(xy)\n",
    "#         means = params[:, :self.latent_dim]\n",
    "#         covs = torch.diag_embed(torch.exp(params[:, self.latent_dim:]) + eps)\n",
    "#         return MultivariateNormal(means, covariance_matrix=covs)\n",
    "\n",
    "#     def prior(self, x: torch.Tensor, eps: float = 1e-8):\n",
    "#         params = self.prior_network(x)\n",
    "#         means = params[:, :self.latent_dim]\n",
    "#         covs = torch.diag_embed(torch.exp(params[:, self.latent_dim:]) + eps)\n",
    "#         return MultivariateNormal(means, covariance_matrix=covs)\n",
    "\n",
    "#     def forward(\n",
    "#         self,\n",
    "#         x: torch.Tensor,\n",
    "#         y: torch.Tensor,\n",
    "#         kl_weight: float = 1.0,\n",
    "#         compute_loss: bool = True,\n",
    "#     ):\n",
    "#         z_recog_dist = self.recognize(x, y)\n",
    "#         z = z_recog_dist.rsample()\n",
    "#         # Reconstruction of y\n",
    "#         if not compute_loss:\n",
    "#             y_recon = self.reconstruct(x, z)\n",
    "#             return CVAEOutput(\n",
    "#                 recog_pass=True,\n",
    "#                 x=x,\n",
    "#                 y=y,\n",
    "#                 z_recog_dist=z_recog_dist,\n",
    "#                 z_recog_sample=z,\n",
    "#                 y_recon=y_recon,\n",
    "#             )\n",
    "#         # Compute loss\n",
    "#         y_recon = self.reconstruct(x, z, raw=True)\n",
    "#         loss_recon = self.loss(y_recon, y).mean()\n",
    "#         z_prior_dist = self.prior(x)\n",
    "#         loss_kl = kl_divergence(z_recog_dist, z_prior_dist).mean()\n",
    "#         loss = loss_recon + kl_weight * loss_kl\n",
    "#         if self.y_dim == 1:\n",
    "#             y_recon = F.sigmoid(y_recon)\n",
    "#         else:\n",
    "#             y_recon = F.softmax(y_recon, dim=-1)\n",
    "#         return CVAEOutput(\n",
    "#             recog_pass=True,\n",
    "#             x=x,\n",
    "#             y=y,\n",
    "#             z_prior_dist=z_prior_dist,\n",
    "#             z_recog_dist=z_recog_dist,\n",
    "#             z_recog_sample=z,\n",
    "#             y_recon=y_recon,\n",
    "#             loss=loss,\n",
    "#             loss_recon=loss_recon,\n",
    "#             loss_kl=loss_kl,\n",
    "#         )\n",
    "\n",
    "#     def generate(\n",
    "#         self,\n",
    "#         x: torch.Tensor,\n",
    "#         y: Optional[torch.Tensor] = None,\n",
    "#         sample: bool = False,\n",
    "#     ):\n",
    "#         z_prior_dist = self.prior(x)\n",
    "#         if sample:\n",
    "#             z = z_prior_dist.sample()\n",
    "#         else:\n",
    "#             z = z_prior_dist.mean\n",
    "#         xz = torch.concatenate((x, z), dim=1)\n",
    "#         y_gen = self.gen_network(xz)\n",
    "#         loss_gen = None if y is None else self.loss(y_gen, y)\n",
    "#         if self.y_dim == 1:\n",
    "#             y_gen = F.sigmoid(y_gen)\n",
    "#         else:\n",
    "#             y_gen = F.softmax(y_gen, dim=-1)\n",
    "#         return CVAEOutput(\n",
    "#             recog_pass=False,\n",
    "#             x=x,\n",
    "#             y=y_gen,\n",
    "#             z_prior_dist=z_prior_dist,\n",
    "#             z_prior_sample=z,\n",
    "#             loss_gen=loss_gen,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_proportion: float = 0.7):\n",
    "    station_1 = pd.read_csv(\n",
    "        './station_1_dummy.csv',\n",
    "        header=0,\n",
    "        parse_dates=[0],\n",
    "        dtype={1: 'category'},\n",
    "        date_format='%d/%m/%Y',\n",
    "    )\n",
    "    station_2 = pd.read_csv(\n",
    "        './station_2_dummy.csv',\n",
    "        header=0,\n",
    "        parse_dates=[0],\n",
    "        dtype={1: 'category'},\n",
    "        date_format='%d/%m/%Y',\n",
    "    )\n",
    "    station_3 = pd.read_csv(\n",
    "        './station_3_dummy.csv',\n",
    "        header=0,\n",
    "        parse_dates=[0],\n",
    "        dtype={1: 'category'},\n",
    "        date_format='%d/%m/%Y',\n",
    "    )\n",
    "    station_1 = station_1.drop(columns=['station'])\n",
    "    station_2 = station_2.drop(columns=['station'])\n",
    "    station_3 = station_3.drop(columns=['station'])\n",
    "    station_1 = station_2.dropna()\n",
    "    station_2 = station_3.dropna()\n",
    "    stations = pd.merge(station_3, station_2, how='left', on='date', suffixes=('_s3', None))\n",
    "    stations = pd.merge(stations, station_1, how='left', on='date', suffixes=('_s2', '_s1'))\n",
    "    stations['month_cos'] = np.cos(2 * np.pi * stations['date'].dt.month / 13)\n",
    "    stations['month_sin'] = np.sin(2 * np.pi * stations['date'].dt.month / 13)\n",
    "    stations['year'] = stations['date'].dt.year\n",
    "    stations.sort_values(by='date', axis=0, ignore_index=True, inplace=True)\n",
    "    no_s3_data = stations['temperature_s3'].isna()\n",
    "    exploration_split = stations[no_s3_data]\n",
    "    train_test_splits = stations[~no_s3_data]\n",
    "    train_size = int(train_test_splits.shape[0] * train_proportion)\n",
    "    train_split = train_test_splits[:train_size]\n",
    "    test_split = train_test_splits[train_size:]\n",
    "    x_columns = [\n",
    "        'temperature_s1', 'precipitation_s1', 'humidity_s1', 'atmospheric_pressure_s1', 'dew_point_s1',\n",
    "        'temperature_s2', 'precipitation_s2', 'humidity_s2', 'atmospheric_pressure_s2', 'dew_point_s2',\n",
    "        'month_cos', 'month_sin', 'year',\n",
    "    ]\n",
    "    y_columns = [\n",
    "        'temperature_s3', 'precipitation_s3', 'humidity_s3', 'atmospheric_pressure_s3', 'dew_point_s3',\n",
    "    ]\n",
    "    return (\n",
    "        (train_split[x_columns], train_split[y_columns]),\n",
    "        (test_split[x_columns], test_split[y_columns]),\n",
    "        (exploration_split[x_columns], None),\n",
    "    )\n",
    "\n",
    "\n",
    "class StationsDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        X: pd.DataFrame,\n",
    "        y: pd.DataFrame,\n",
    "        normalize: Optional['StationsDataset'] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._X = X.to_numpy(dtype=np.float32)\n",
    "        self._y = y.to_numpy(dtype=np.float32)\n",
    "        if normalize is None:\n",
    "            self._X_mean = self._X[:, :-3].mean(axis=0, keepdims=True)\n",
    "            self._X_std = self._X[:, :-3].std(axis=0, keepdims=True)\n",
    "            self._year_min = self._X[:, -1].min()\n",
    "            self._year_max = self._X[:, -1].max()\n",
    "            self._y_mean = self._y.mean(axis=0, keepdims=True)\n",
    "            self._y_std = self._y.std(axis=0, keepdims=True)\n",
    "        else:\n",
    "            self._X_mean = normalize._X_mean\n",
    "            self._X_std = normalize._X_std\n",
    "            self._year_min = normalize._year_min\n",
    "            self._year_max = normalize._year_max\n",
    "            self._y_mean = normalize._y_mean\n",
    "            self._y_std = normalize._y_std\n",
    "        self._X[:, :-3] = (self._X[:, :-3] - self._X_mean) / self._X_std\n",
    "        self._X[:, -1] = 2 * (self._X[:, -1] - self._year_min) / (self._year_max - self._year_min) - 1\n",
    "        self._y[:] = (self._y - self._y_mean) / self._y_std\n",
    "        self.X = torch.from_numpy(self._X).float()\n",
    "        self.y = torch.from_numpy(self._y).float()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch_size = 100\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 300\n",
    "x_dim = 13\n",
    "y_dim = 5\n",
    "latent_dim = 2\n",
    "prior_hidden_dim = [128, 64]\n",
    "gen_hidden_dim = [256, 128, 64]\n",
    "recog_hidden_dim = [256, 128, 64]\n",
    "kl_weight = 1.2\n",
    "\n",
    "train_split, test_split, exploration_split = get_data()\n",
    "train_dataset = StationsDataset(*train_split)\n",
    "test_dataset = StationsDataset(*test_split, normalize=train_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 13])\n",
      "torch.Size([7, 5])\n"
     ]
    }
   ],
   "source": [
    "train_batch = next(iter(train_loader))\n",
    "\n",
    "print(train_batch[0].shape)\n",
    "print(train_batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(\n",
    "#     model: CVAE,\n",
    "#     dataloader: DataLoader,\n",
    "#     optimizer: torch.optim.Optimizer,\n",
    "#     kl_weight: float,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model on the given data.\n",
    "    \n",
    "#     Args:\n",
    "#         model (nn.Module): The model to train.\n",
    "#         dataloader (torch.utils.data.DataLoader): The data loader.\n",
    "#         optimizer: The optimizer.\n",
    "#     \"\"\"\n",
    "#     model.train()  # Set the model to training mode\n",
    "#     loss_total = 0.0\n",
    "#     loss_recon = 0.0\n",
    "#     loss_kl = 0.0\n",
    "#     loss_gen = 0.0\n",
    "#     for x, y in dataloader:\n",
    "#         x = x.to(device)\n",
    "#         y = y.to(device)\n",
    "#         optimizer.zero_grad()  # Zero the gradients\n",
    "#         output = model(x, y, kl_weight, compute_loss=True)  # Forward pass\n",
    "#         loss = output.loss\n",
    "#         loss.backward()\n",
    "#         optimizer.step()  # Update the model parameters\n",
    "#         loss_total += loss.item()\n",
    "#         loss_recon += output.loss_recon.item()\n",
    "#         loss_kl += output.loss_kl.item()\n",
    "#         output = model.generate(x, y)\n",
    "#         loss_gen += output.loss_gen.item()\n",
    "#     n_batchs = len(dataloader)\n",
    "#     loss_total /= n_batchs\n",
    "#     loss_recon /= n_batchs\n",
    "#     loss_kl /= n_batchs\n",
    "#     loss_gen /= n_batchs\n",
    "#     return loss_total, loss_recon, loss_kl, loss_gen\n",
    "\n",
    "\n",
    "# def test(model: CVAE, dataloader: DataLoader):\n",
    "#     \"\"\"\n",
    "#     Tests the model on the given data.\n",
    "    \n",
    "#     Args:\n",
    "#         model (nn.Module): The model to test.\n",
    "#         dataloader (torch.utils.data.DataLoader): The data loader.\n",
    "#     \"\"\"\n",
    "#     model.eval()  # Set the model to evaluation mode\n",
    "#     loss_total = 0.0\n",
    "#     loss_recon = 0.0\n",
    "#     loss_kl = 0.0\n",
    "#     loss_gen = 0.0\n",
    "#     with torch.no_grad():\n",
    "#         for x, y in dataloader:\n",
    "#             x = x.to(device)\n",
    "#             y = y.to(device)\n",
    "#             output = model(x, y, compute_loss=True)  # Forward pass\n",
    "#             loss_total += output.loss.item()\n",
    "#             loss_recon += output.loss_recon.item()\n",
    "#             loss_kl += output.loss_kl.item()\n",
    "#             output = model.generate(x, y)\n",
    "#             loss_gen += output.loss_gen.item()\n",
    "#     n_batchs = len(dataloader)\n",
    "#     loss_total /= n_batchs\n",
    "#     loss_recon /= n_batchs\n",
    "#     loss_kl /= n_batchs\n",
    "#     loss_gen /= n_batchs\n",
    "#     return loss_total, loss_recon, loss_kl, loss_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Training Conditional Variational Autoencoder...\")\n",
    "# model_CVAE = CVAE(\n",
    "#     x_dim=x_dim,\n",
    "#     y_dim=y_dim,\n",
    "#     latent_dim=latent_dim,\n",
    "#     prior_hidden_dim=prior_hidden_dim,\n",
    "#     gen_hidden_dim=gen_hidden_dim,\n",
    "#     recog_hidden_dim=recog_hidden_dim,\n",
    "# ).to(device)\n",
    "\n",
    "# print(model_CVAE)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model_CVAE.parameters(), lr=learning_rate)\n",
    "\n",
    "# train_loss_history = []\n",
    "# test_loss_history = []\n",
    "# for epoch in trange(1, num_epochs + 1, desc='Training', unit='epoch'):\n",
    "#     train_losses = train(model_CVAE, train_loader, optimizer, kl_weight)\n",
    "#     test_losses = test(model_CVAE, test_loader)\n",
    "#     train_loss_history.append(train_losses)\n",
    "#     test_loss_history.append(test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(8, 8))\n",
    "# # Train data\n",
    "# cls_mask = train_split[1].astype(bool)\n",
    "# plt.scatter(train_split[0][cls_mask, 0], train_split[0][cls_mask, 1], color='orange', label='Train 1')\n",
    "# plt.scatter(train_split[0][~cls_mask, 0], train_split[0][~cls_mask, 1], color='cyan', label='Train 0')\n",
    "# # Test data\n",
    "# cls_mask = test_split[1].astype(bool)\n",
    "# plt.scatter(test_split[0][cls_mask, 0], test_split[0][cls_mask, 1], color='red', marker='x', label='Test 1')\n",
    "# plt.scatter(test_split[0][~cls_mask, 0], test_split[0][~cls_mask, 1], color='blue', marker='x', label='Test 1')\n",
    "\n",
    "# plt.title('Training and testing data')\n",
    "# plt.xlabel('x1')\n",
    "# plt.ylabel('x2')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses_label = ('total', 'reconstruction', 'kl', 'generation')\n",
    "\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(10, 8), sharex=True)\n",
    "# axs = axs.ravel()\n",
    "\n",
    "# for i, loss_label in enumerate(losses_label):\n",
    "#     ax = axs[i]\n",
    "#     ax.plot(\n",
    "#         range(1, len(train_loss_history) + 1),\n",
    "#         [l[i] for l in train_loss_history],\n",
    "#         label='Training',\n",
    "#     )\n",
    "#     ax.plot(\n",
    "#         range(1, len(test_loss_history) + 1),\n",
    "#         [l[i] for l in test_loss_history],\n",
    "#         label='Testing',\n",
    "#     )\n",
    "#     ax.set_xlabel('Epochs')\n",
    "#     ax.set_ylabel(f'{loss_label.capitalize()} loss')\n",
    "#     ax.set_title(f'{loss_label.capitalize()} loss evolution')\n",
    "#     ax.grid()\n",
    "#     ax.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent space projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_latent_space_projections(model: CVAE, dataloader: DataLoader):\n",
    "#     model.eval()\n",
    "#     prior_space = []\n",
    "#     xy_recog_space = []\n",
    "#     x1_recog_space = []\n",
    "#     with torch.no_grad():\n",
    "#         for x, y in dataloader:\n",
    "#             x = x.to(device)\n",
    "#             y = y.to(device)\n",
    "#             prior_dist = model.prior(x)\n",
    "#             prior_space.append(prior_dist.mean.detach().cpu().numpy())\n",
    "#             xy_recog_dist = model.recognize(x, y)\n",
    "#             xy_recog_space.append(xy_recog_dist.mean.detach().cpu().numpy())\n",
    "#             x1_recog_dist = model.recognize(x, torch.ones_like(y))\n",
    "#             x1_recog_space.append(x1_recog_dist.mean.detach().cpu().numpy())\n",
    "#     prior_space = np.concatenate(prior_space, axis=0)\n",
    "#     xy_recog_space = np.concatenate(xy_recog_space, axis=0)\n",
    "#     x1_recog_space = np.concatenate(x1_recog_space, axis=0)\n",
    "#     return prior_space, xy_recog_space, x1_recog_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior_space, xy_recog_space, x1_recog_space = get_latent_space_projections(model_CVAE, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "# oax, pax, rxy_ax, rx1_ax = axs.ravel()\n",
    "\n",
    "# oax.scatter(test_split[0][cls_mask, 0], test_split[0][cls_mask, 1], label='Class 1', color='orange')\n",
    "# oax.scatter(test_split[0][~cls_mask, 0], test_split[0][~cls_mask, 1], label='Class 0', color='cyan')\n",
    "# oax.set_xlabel('x1')\n",
    "# oax.set_ylabel('x2')\n",
    "# oax.set_title('Test data')\n",
    "# oax.legend()\n",
    "\n",
    "# pax.scatter(prior_space[cls_mask, 0], prior_space[cls_mask, 1], label='Class 1', color='orange')\n",
    "# pax.scatter(prior_space[~cls_mask, 0], prior_space[~cls_mask, 1], label='Class 0', color='cyan')\n",
    "# pax.set_xlabel('x1')\n",
    "# pax.set_ylabel('x2')\n",
    "# pax.set_title('Projection into prior(x) latent space')\n",
    "# pax.legend()\n",
    "\n",
    "# rxy_ax.scatter(xy_recog_space[cls_mask, 0], xy_recog_space[cls_mask, 1], label='Class 1', color='orange')\n",
    "# rxy_ax.scatter(xy_recog_space[~cls_mask, 0], xy_recog_space[~cls_mask, 1], label='Class 0', color='cyan')\n",
    "# rxy_ax.set_xlabel('x1')\n",
    "# rxy_ax.set_ylabel('x2')\n",
    "# rxy_ax.set_title('Projection into recognize(x,y) latent space')\n",
    "# rxy_ax.legend()\n",
    "\n",
    "# rx1_ax.scatter(x1_recog_space[cls_mask, 0], x1_recog_space[cls_mask, 1], label='Class 1', color='orange')\n",
    "# rx1_ax.scatter(x1_recog_space[~cls_mask, 0], x1_recog_space[~cls_mask, 1], label='Class 0', color='cyan')\n",
    "# rx1_ax.set_xlabel('x1')\n",
    "# rx1_ax.set_ylabel('x2')\n",
    "# rx1_ax.set_title('Projection into recognize(x,1) latent space')\n",
    "# rx1_ax.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the prior network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(model: CVAE, dataloader: DataLoader):\n",
    "#     model.eval()\n",
    "#     y_pred = []\n",
    "#     with torch.no_grad():\n",
    "#         for x, _ in dataloader:\n",
    "#             x = x.to(device)\n",
    "#             output = model.generate(x)\n",
    "#             y_pred.append(output.y.detach().cpu().numpy())\n",
    "#     y_pred = np.concatenate(y_pred, axis=0)\n",
    "#     return y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior_y_pred = predict(model_CVAE, test_loader) > 0.5\n",
    "\n",
    "# prior_fns = np.logical_and(cls_mask, ~prior_y_pred)\n",
    "# prior_fps = np.logical_and(~cls_mask, prior_y_pred)\n",
    "\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "# oax, pax, rxy_ax, rx1_ax = axs.ravel()\n",
    "\n",
    "# oax.scatter(test_split[0][cls_mask, 0], test_split[0][cls_mask, 1], label='Class 1', color='orange')\n",
    "# oax.scatter(test_split[0][~cls_mask, 0], test_split[0][~cls_mask, 1], label='Class 0', color='cyan')\n",
    "# oax.scatter(test_split[0][prior_fns, 0], test_split[0][prior_fns, 1], label='FNs', color='red', marker='x')\n",
    "# oax.scatter(test_split[0][prior_fps, 0], test_split[0][prior_fps, 1], label='FPs', color='blue', marker='x')\n",
    "# oax.set_xlabel('x1')\n",
    "# oax.set_ylabel('x2')\n",
    "# oax.set_title('Test data')\n",
    "# oax.legend()\n",
    "\n",
    "# pax.scatter(prior_space[cls_mask, 0], prior_space[cls_mask, 1], label='Class 1', color='orange')\n",
    "# pax.scatter(prior_space[~cls_mask, 0], prior_space[~cls_mask, 1], label='Class 0', color='cyan')\n",
    "# pax.scatter(prior_space[prior_fns, 0], prior_space[prior_fns, 1], label='FNs', color='red', marker='x')\n",
    "# pax.scatter(prior_space[prior_fps, 0], prior_space[prior_fps, 1], label='FPs', color='blue', marker='x')\n",
    "# pax.set_xlabel('x1')\n",
    "# pax.set_ylabel('x2')\n",
    "# pax.set_title('Projection into prior(x) latent space')\n",
    "# pax.legend()\n",
    "\n",
    "# rxy_ax.scatter(xy_recog_space[cls_mask, 0], xy_recog_space[cls_mask, 1], label='Class 1', color='orange')\n",
    "# rxy_ax.scatter(xy_recog_space[~cls_mask, 0], xy_recog_space[~cls_mask, 1], label='Class 0', color='cyan')\n",
    "# rxy_ax.scatter(xy_recog_space[prior_fns, 0], xy_recog_space[prior_fns, 1], label='FNs', color='red', marker='x')\n",
    "# rxy_ax.scatter(xy_recog_space[prior_fps, 0], xy_recog_space[prior_fps, 1], label='FPs', color='blue', marker='x')\n",
    "# rxy_ax.set_xlabel('x1')\n",
    "# rxy_ax.set_ylabel('x2')\n",
    "# rxy_ax.set_title('Projection into recognize(x,y) latent space')\n",
    "# rxy_ax.legend()\n",
    "\n",
    "# rx1_ax.scatter(x1_recog_space[cls_mask, 0], x1_recog_space[cls_mask, 1], label='Class 1', color='orange')\n",
    "# rx1_ax.scatter(x1_recog_space[~cls_mask, 0], x1_recog_space[~cls_mask, 1], label='Class 0', color='cyan')\n",
    "# rx1_ax.scatter(x1_recog_space[prior_fns, 0], x1_recog_space[prior_fns, 1], label='FNs', color='red', marker='x')\n",
    "# rx1_ax.scatter(x1_recog_space[prior_fps, 0], x1_recog_space[prior_fps, 1], label='FPs', color='blue', marker='x')\n",
    "# rx1_ax.set_xlabel('x1')\n",
    "# rx1_ax.set_ylabel('x2')\n",
    "# rx1_ax.set_title('Projection into recognize(x,1) latent space')\n",
    "# rx1_ax.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the recognition network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def importance_predict(model: CVAE, dataloader: DataLoader, num_samples: int = 5):\n",
    "#     model.eval()\n",
    "#     y_pred = []\n",
    "#     with torch.no_grad():\n",
    "#         for x, y in dataloader:\n",
    "#             x = x.to(device)\n",
    "#             y_hyp = torch.ones_like(y).to(device)\n",
    "#             recog_dist = model.recognize(x, y_hyp)\n",
    "#             prior_dist = model.prior(x)\n",
    "#             batch_y_pred = 0.0\n",
    "#             for _ in range(num_samples):\n",
    "#                 z = recog_dist.sample()\n",
    "#                 sample_probs = model.reconstruct(x, z).flatten()\n",
    "#                 sample_probs *= torch.exp(prior_dist.log_prob(z)) / num_samples\n",
    "#                 sample_probs /= torch.exp(recog_dist.log_prob(z))\n",
    "#                 batch_y_pred += sample_probs\n",
    "#             y_pred.append(batch_y_pred.detach().cpu().numpy())\n",
    "#     y_pred = np.concatenate(y_pred, axis=0)\n",
    "#     return y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recog_y_pred = importance_predict(model_CVAE, test_loader) > 0.5\n",
    "\n",
    "# prior_fns = np.logical_and(cls_mask, ~recog_y_pred)\n",
    "# prior_fps = np.logical_and(~cls_mask, recog_y_pred)\n",
    "\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "# oax, pax, rxy_ax, rx1_ax = axs.ravel()\n",
    "\n",
    "# oax.scatter(test_split[0][cls_mask, 0], test_split[0][cls_mask, 1], label='Class 1', color='orange')\n",
    "# oax.scatter(test_split[0][~cls_mask, 0], test_split[0][~cls_mask, 1], label='Class 0', color='cyan')\n",
    "# oax.scatter(test_split[0][prior_fns, 0], test_split[0][prior_fns, 1], label='FNs', color='red', marker='x')\n",
    "# oax.scatter(test_split[0][prior_fps, 0], test_split[0][prior_fps, 1], label='FPs', color='blue', marker='x')\n",
    "# oax.set_xlabel('x1')\n",
    "# oax.set_ylabel('x2')\n",
    "# oax.set_title('Test data')\n",
    "# oax.legend()\n",
    "\n",
    "# pax.scatter(prior_space[cls_mask, 0], prior_space[cls_mask, 1], label='Class 1', color='orange')\n",
    "# pax.scatter(prior_space[~cls_mask, 0], prior_space[~cls_mask, 1], label='Class 0', color='cyan')\n",
    "# pax.scatter(prior_space[prior_fns, 0], prior_space[prior_fns, 1], label='FNs', color='red', marker='x')\n",
    "# pax.scatter(prior_space[prior_fps, 0], prior_space[prior_fps, 1], label='FPs', color='blue', marker='x')\n",
    "# pax.set_xlabel('x1')\n",
    "# pax.set_ylabel('x2')\n",
    "# pax.set_title('Projection into prior(x) latent space')\n",
    "# pax.legend()\n",
    "\n",
    "# rxy_ax.scatter(xy_recog_space[cls_mask, 0], xy_recog_space[cls_mask, 1], label='Class 1', color='orange')\n",
    "# rxy_ax.scatter(xy_recog_space[~cls_mask, 0], xy_recog_space[~cls_mask, 1], label='Class 0', color='cyan')\n",
    "# rxy_ax.scatter(xy_recog_space[prior_fns, 0], xy_recog_space[prior_fns, 1], label='FNs', color='red', marker='x')\n",
    "# rxy_ax.scatter(xy_recog_space[prior_fps, 0], xy_recog_space[prior_fps, 1], label='FPs', color='blue', marker='x')\n",
    "# rxy_ax.set_xlabel('x1')\n",
    "# rxy_ax.set_ylabel('x2')\n",
    "# rxy_ax.set_title('Projection into recognize(x,y) latent space')\n",
    "# rxy_ax.legend()\n",
    "\n",
    "# rx1_ax.scatter(x1_recog_space[cls_mask, 0], x1_recog_space[cls_mask, 1], label='Class 1', color='orange')\n",
    "# rx1_ax.scatter(x1_recog_space[~cls_mask, 0], x1_recog_space[~cls_mask, 1], label='Class 0', color='cyan')\n",
    "# rx1_ax.scatter(x1_recog_space[prior_fns, 0], x1_recog_space[prior_fns, 1], label='FNs', color='red', marker='x')\n",
    "# rx1_ax.scatter(x1_recog_space[prior_fps, 0], x1_recog_space[prior_fps, 1], label='FPs', color='blue', marker='x')\n",
    "# rx1_ax.set_xlabel('x1')\n",
    "# rx1_ax.set_ylabel('x2')\n",
    "# rx1_ax.set_title('Projection into recognize(x,1) latent space')\n",
    "# rx1_ax.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior_tns = np.logical_and(~cls_mask, ~prior_y_pred).sum()\n",
    "# prior_fps = np.logical_and(~cls_mask, prior_y_pred).sum()\n",
    "# prior_fns = np.logical_and(cls_mask, ~prior_y_pred).sum()\n",
    "# prior_tps = np.logical_and(cls_mask, prior_y_pred).sum()\n",
    "# prior_cmatrix = np.array([[prior_tns, prior_fps], [prior_fns, prior_tps]])\n",
    "\n",
    "# recog_tns = np.logical_and(~cls_mask, ~recog_y_pred).sum()\n",
    "# recog_fps = np.logical_and(~cls_mask, recog_y_pred).sum()\n",
    "# recog_fns = np.logical_and(cls_mask, ~recog_y_pred).sum()\n",
    "# recog_tps = np.logical_and(cls_mask, recog_y_pred).sum()\n",
    "# recog_cmatrix = np.array([[recog_tns, recog_fps], [recog_fns, recog_tps]])\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# display = ConfusionMatrixDisplay(prior_cmatrix)\n",
    "# display.plot(ax=axs[0], colorbar=False, cmap='Blues')\n",
    "# axs[0].set_title(f'Confusion Matrix from prior(x) predictions')\n",
    "\n",
    "# display = ConfusionMatrixDisplay(recog_cmatrix)\n",
    "# display.plot(ax=axs[1], colorbar=False, cmap='Blues')\n",
    "# axs[1].set_title(f'Confusion Matrix from recognize(x,1) predictions')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
